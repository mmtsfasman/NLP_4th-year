{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контрольная *ВАР. 1*\n",
    "**Цфасман Маша**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1**\n",
    "\n",
    "1) Для лексемы \"партия\" выберите 2 контекста со значением политическая партия и 2 контекста со значением партия товара длиной 8-12 слов. Из каждого контекста выберите значимые леммы. \n",
    "\n",
    "\n",
    "**политика**:\n",
    "* \"ЛДПР первая партия, которая даже в своём названии указала на приверженность либерализму - Либерально-демократическая партия России.\"\n",
    "* \"Политической партией называют непрерывно действующую организацию, существующую как на национальном, так и на местном уровнях, нацеленную на получение и отправление власти и стремящуюся с этой целью к широкой массовой поддержке.\"\n",
    "\n",
    "**товары**:\n",
    "* \" На Внуковской таможне задержали целую партию игрушек из Китая. Сотни детских товаров из Поднебесной попытались в Москву в обход всех законов.\"\n",
    "* \"Партия вина помещается в специально подготовленные отсеки, называемые казами. Каждую партию вина, находящуюся в отдельной казе, снабжают деревянными бирками с чёткими надписями, где указывают наименование напитка, его производителя, тип, кондиции и другие данные.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "from pprint import pprint\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_polit_1 = \"ЛДПР первая партия, которая даже в своём названии указала на приверженность либерализму - Либерально-демократическая партия России.\"\n",
    "cont_polit_2 = \"Политической партией называют непрерывно действующую организацию, существующую как на национальном, так и на местном уровнях, нацеленную на получение и отправление власти и стремящуюся с этой целью к широкой массовой поддержке.\"\n",
    "cont_goods_1 = \"На Внуковской таможне задержали целую партию игрушек из Китая. Сотни детских товаров из Поднебесной попытались в Москву в обход всех законов.\"\n",
    "cont_goods_2 = \"Партия вина помещается в специально подготовленные отсеки, называемые казами. Каждую партию вина, находящуюся в отдельной казе, снабжают деревянными бирками с чёткими надписями, где указывают наименование напитка, его производителя, тип, кондиции и другие данные.\"\n",
    "\n",
    "def load_stop_words(stop_filename):\n",
    "\t''' загрузить список стоп-слов из файла, одно слово на строке '''\n",
    "\twith open(stop_filename, encoding = 'utf-8') as f:\n",
    "\t\tstopwords = [w.strip() for w in f.readlines() if w.strip()]\n",
    "\treturn set(stopwords)\n",
    "\n",
    "stopw = \"./stoplist_russian.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лдпр', 'партия', 'который', 'название', 'указывать', 'приверженность', 'либерализм', 'либерально', 'демократический', 'партия', 'россия']\n",
      "['политический', 'партия', 'называть', 'непрерывно', 'действующий', 'организация', 'существовать', 'как', 'национальный', 'так', 'местный', 'уровень', 'нацеливать', 'получение', 'отправление', 'власть', 'стремиться', 'цель', 'к', 'широкий', 'массовый', 'поддержка']\n",
      "['внуковский', 'таможня', 'задерживать', 'целый', 'партия', 'игрушка', 'из', 'китай', 'сотня', 'детский', 'товар', 'из', 'поднебесный', 'попытаться', 'москва', 'обход', 'весь', 'закон']\n",
      "['партия', 'вино', 'помещаться', 'специально', 'подготовить', 'отсек', 'называть', 'каз', 'партия', 'вино', 'находиться', 'отдельный', 'каз', 'снабжать', 'деревянный', 'бирка', 'четкий', 'надпись', 'где', 'указывать', 'наименование', 'напиток', 'его', 'производитель', 'тип', 'кондиция', 'другой', 'данные']\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(raw_text):\n",
    "    clean_text = re.sub('\\W+', ' ', raw_text) # \\W = [^a-zA-Z0-9_]\n",
    "    return clean_text\n",
    "\n",
    "def lemmatize(input):\n",
    "    return [lemma.strip() for lemma in m.lemmatize(preprocessing(input.lower())) if lemma.strip()]\n",
    "\n",
    "def remove_stop_words(lemmas, stopwords):\n",
    "    return [word for word in lemmas if word not in stopwords]\n",
    "\n",
    "\n",
    "all_cont = [cont_polit_1, cont_polit_2, cont_goods_1, cont_goods_2]\n",
    "all_cont_clean = []\n",
    "\n",
    "for text in all_cont:\n",
    "    n = remove_stop_words(lemmatize(text), load_stop_words(stopw))\n",
    "    all_cont_clean.append(n)\n",
    "    print(remove_stop_words(lemmatize(text), load_stop_words(stopw)))\n",
    "\n",
    "cont_polit_1_clean = all_cont_clean[0]\n",
    "cont_polit_2_clean = all_cont_clean[1]\n",
    "cont_goods_1_clean = all_cont_clean[2]\n",
    "cont_goods_2_clean = all_cont_clean[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Вычислите коэффициент Дайса для попарной близости контекстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-b27fee4d9d73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_cont_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcont1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcont2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mcont2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'context number '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'& context number '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'DICE: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_coefficient2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "def dice_coefficient(a, b):\n",
    "    \"\"\"dice coefficient 2nt/na + nb.\"\"\"\n",
    "    a_bigrams = set(a)\n",
    "    b_bigrams = set(b)\n",
    "    overlap = len([a for a_bigrams & b_bigrams])\n",
    "    return overlap * 2.0/(len(a_bigrams) + len(b_bigrams))\n",
    "\n",
    "def dice_coefficient2(a, b):\n",
    "    \"\"\"dice coefficient 2nt/na + nb.\"\"\"\n",
    "    if not len(a) or not len(b): return 0.0\n",
    "    if len(a) == 1:  \n",
    "        a=a+u'.'\n",
    "    if len(b) == 1:  \n",
    "        b=b+u'.'\n",
    "    \n",
    "    a_bigram_list=[]\n",
    "    for i in range(len(a)-1):\n",
    "        a_bigram_list.append(a[i:i+2])\n",
    "    b_bigram_list=[]\n",
    "    for i in range(len(b)-1):\n",
    "        b_bigram_list.append(b[i:i+2])\n",
    "      \n",
    "    a_bigrams = set(a_bigram_list)\n",
    "    b_bigrams = set(b_bigram_list)\n",
    "    overlap = len(a_bigrams & b_bigrams)\n",
    "    dice_coeff = overlap * 2.0/(len(a_bigrams) + len(b_bigrams))\n",
    "    return dice_coeff\n",
    "\n",
    "\n",
    "for n1, cont1 in enumerate(all_cont_clean):\n",
    "    for n2, cont2 in enumerate(all_cont_clean):\n",
    "        if cont1 != cont2:\n",
    "            print(cont1&cont2)\n",
    "            print('context number ' + str(n1) + '& context number ' + str(n2) + 'DICE: ' + str(dice_coefficient2(cont1, cont2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#не успела исправить((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3) Упорядочите контексты по близости. \n",
    "В ответе приведите код или подсчеты, а также получившийся порядок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#не успела исправить((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2**\n",
    "\n",
    "Задание на WordNet\n",
    "\n",
    "1) Найти все значения (синсеты) для лексемы cup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cup.n.01') a small open container usually used for drinking; usually has a handle\n",
      "Synset('cup.n.02') the quantity a cup will hold\n",
      "Synset('cup.n.03') any cup-shaped concavity\n",
      "Synset('cup.n.04') a United States liquid unit equal to 8 fluid ounces\n",
      "Synset('cup.n.05') cup-shaped plant organ\n",
      "Synset('cup.n.06') a punch served in a pitcher instead of a punch bowl\n",
      "Synset('cup.n.07') the hole (or metal container in the hole) on a golf green\n",
      "Synset('cup.n.08') a large metal vessel with two handles that is awarded as a trophy to the winner of a competition\n",
      "Synset('cup.v.01') form into the shape of a cup\n",
      "Synset('cup.v.02') put into a cup\n",
      "Synset('cup.v.03') treat by applying evacuated cups to the patient's skin\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "cup = wordnet.synsets('cup')\n",
    "for ss in cup:\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) найти гиперонимы для значения лексемы cup - кубок, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('trophy.n.02') something given as a token of victory\n"
     ]
    }
   ],
   "source": [
    "for ss in wordnet.synset('cup.n.08').hypernyms():\n",
    "    print(ss, ss.definition())\n",
    "#wordnet.synset('cup.n.08').hypernyms() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**то есть это *трофей*** (если я правильно поняла что имеется ввиду под словом \"кубок\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) вычислите одним из сопобов расстояние: (tea, coffee), (container, aretefact). Какое расстояние меньше. Соответствует ли это Вашей интуиции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a beverage made by steeping tea leaves in water\n",
      "a beverage consisting of an infusion of ground coffee beans\n",
      "0.8888888888888888\n",
      "any of several small trees and shrubs native to the tropical Old World yielding coffee beans\n",
      "0.2222222222222222\n",
      "a seed of the coffee tree; ground to make coffee\n",
      "0.2222222222222222\n",
      "a medium brown to dark-brown color\n",
      "0.2222222222222222\n",
      "a light midafternoon meal of tea and sandwiches or cakes\n",
      "a beverage consisting of an infusion of ground coffee beans\n",
      "0.6666666666666666\n",
      "any of several small trees and shrubs native to the tropical Old World yielding coffee beans\n",
      "0.21052631578947367\n",
      "a seed of the coffee tree; ground to make coffee\n",
      "0.21052631578947367\n",
      "a medium brown to dark-brown color\n",
      "0.11764705882352941\n",
      "a tropical evergreen shrub or small tree extensively cultivated in e.g. China and Japan and India; source of tea leaves\n",
      "a beverage consisting of an infusion of ground coffee beans\n",
      "0.2222222222222222\n",
      "any of several small trees and shrubs native to the tropical Old World yielding coffee beans\n",
      "0.8181818181818182\n",
      "a seed of the coffee tree; ground to make coffee\n",
      "0.36363636363636365\n",
      "a medium brown to dark-brown color\n",
      "0.1\n",
      "a reception or party at which tea is served\n",
      "a beverage consisting of an infusion of ground coffee beans\n",
      "0.2222222222222222\n",
      "any of several small trees and shrubs native to the tropical Old World yielding coffee beans\n",
      "0.1\n",
      "a seed of the coffee tree; ground to make coffee\n",
      "0.1\n",
      "a medium brown to dark-brown color\n",
      "0.2222222222222222\n",
      "dried leaves of the tea shrub; used to make tea\n",
      "a beverage consisting of an infusion of ground coffee beans\n",
      "0.5882352941176471\n",
      "any of several small trees and shrubs native to the tropical Old World yielding coffee beans\n",
      "0.19047619047619047\n",
      "a seed of the coffee tree; ground to make coffee\n",
      "0.19047619047619047\n",
      "a medium brown to dark-brown color\n",
      "0.10526315789473684\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet_ic\n",
    "ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "tea = wordnet.synsets('tea')\n",
    "coffee = wordnet.synsets('coffee')\n",
    "for ss1 in tea:\n",
    "    print(ss1.definition())\n",
    "    for ss2 in coffee:\n",
    "        print(ss2.definition())\n",
    "        #Wu-Palmer Similarity\n",
    "        print(ss1.wup_similarity(ss2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any object that can be used to hold things (especially a large metal boxlike object of standardized dimensions that can be loaded from one form of transport to another)\n",
      "a man-made object taken as a whole\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "container = wordnet.synsets('container')\n",
    "artefact = wordnet.synsets('artefact')\n",
    "for ss1 in container:\n",
    "    print(ss1.definition())\n",
    "    for ss2 in artefact:\n",
    "        print(ss2.definition())\n",
    "        #Wu-Palmer Similarity\n",
    "        print(ss1.wup_similarity(ss2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Я решила взять Wu-Palmer Similarity. Оказалось, что (tea, coffee) ближе в значении \"жидкости\" ближе, чем (container, aretefact), хотя не сильно. А в остальных значениях - дальше, чем (container, aretefact)**\n",
    "\n",
    "***Хотя мне бы казалось, что в любых значениях кофе к чаю должны быть сильно ближе***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**\n",
    "\n",
    "Возьмите готовую модель word2vec (см. последнее практическое занятие). Вычислите топ 10 слов для слова \"начальник\". Определите топ 5 близких к слову \"начальник\" по русскому ворд-нету: http://ruwordnet.ru/en/ или по РуТез http://www.labinform.ru/pub/ruthes/ (любым способом, опишите, как Вы искали близкие слова). Каков процент пересечения? Какие, полученные в выбранной Вами модели слова, на Ваш взгляд, попали в топ 10 близких ошибочно. Попробуйте прокомментировать, почему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:21:36,231 : INFO : collecting all words and their counts\n",
      "2018-03-05 14:21:36,233 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-05 14:21:36,294 : INFO : collected 30172 word types from a corpus of 68570 raw words and 5432 sentences\n",
      "2018-03-05 14:21:36,295 : INFO : Loading a fresh vocabulary\n",
      "2018-03-05 14:21:36,330 : INFO : min_count=2 retains 6793 unique words (22% of original 30172, drops 23379)\n",
      "2018-03-05 14:21:36,332 : INFO : min_count=2 leaves 45191 word corpus (65% of original 68570, drops 23379)\n",
      "2018-03-05 14:21:36,360 : INFO : deleting the raw counts dictionary of 30172 items\n",
      "2018-03-05 14:21:36,365 : INFO : sample=0.001 downsamples 34 most-common words\n",
      "2018-03-05 14:21:36,366 : INFO : downsampling leaves estimated 37321 word corpus (82.6% of prior 45191)\n",
      "2018-03-05 14:21:36,366 : INFO : estimated required memory for 6793 words and 500 dimensions: 30568500 bytes\n",
      "2018-03-05 14:21:36,392 : INFO : resetting layer weights\n",
      "2018-03-05 14:21:36,501 : INFO : training model with 3 workers on 6793 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-03-05 14:21:36,975 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-05 14:21:36,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-05 14:21:36,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-05 14:21:36,986 : INFO : training on 342850 raw words (186733 effective words) took 0.5s, 389743 effective words/s\n",
      "2018-03-05 14:21:37,223 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-03-05 14:21:37,295 : INFO : saving Word2Vec object under my.model, separately None\n",
      "2018-03-05 14:21:37,296 : INFO : not storing attribute syn0norm\n",
      "2018-03-05 14:21:37,297 : INFO : not storing attribute cum_table\n",
      "2018-03-05 14:21:37,632 : INFO : saved my.model\n",
      "2018-03-05 14:21:37,633 : INFO : loading projection weights from ruscorpora_mean_hs.model.bin\n",
      "2018-03-05 14:21:41,903 : INFO : loaded (281776, 300) matrix from ruscorpora_mean_hs.model.bin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "f = 'text.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)\n",
    "\n",
    "model = gensim.models.Word2Vec(data, size=500, window=10, min_count=2, sg=0)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "model.save('my.model')\n",
    "\n",
    "m = 'ruscorpora_mean_hs.model.bin'\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начальник_S\n",
      "[ 0.00141657 -0.08540501 -0.01739847  0.04126468 -0.01520346 -0.00201775\n",
      "  0.00675521  0.08611108 -0.08708072 -0.08219937]\n",
      "замначальник_S 0.6262381076812744\n",
      "заведующий_S 0.5692601799964905\n",
      "комендант_S 0.5626716017723083\n",
      "дежурный_S 0.5406118631362915\n",
      "инспектор_S 0.5218731760978699\n",
      "шеф_S 0.5208275318145752\n",
      "оперуполномоченный_S 0.49783241748809814\n",
      "начальство_S 0.49532797932624817\n",
      "руководитель_S 0.4885033965110779\n",
      "командир_S 0.4845767617225647\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = 'начальник_S'\n",
    "\n",
    "# есть ли слово в модели? Может быть, и нет\n",
    "if word in model:\n",
    "    print(word)\n",
    "    # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "    print(model[word][:10])\n",
    "    # выдаем 10 ближайших соседей слова:\n",
    "    for i in model.most_similar(positive=[word], topn=10):\n",
    "        # слово + коэффициент косинусной близости\n",
    "        print(i[0], i[1])\n",
    "    print('\\n')\n",
    "else:\n",
    "    # Увы!\n",
    "    print(word + ' is not present in the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ 5 по http://ruwordnet.ru/en/.\n",
    "\n",
    "* ШЕФ\n",
    "* БОСС\n",
    "* НАЧАЛЬНИЦА\n",
    "* ГЛАВА\n",
    "* КУРАТОР\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как ни странно, все слова более менее подходят, самое странное - оперуполномоченный, но в принципе это тоже начальник))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "Найдите лишнее слово; \"говорить, сказать, писать, удивляться\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "удивляться_V\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('говорить_V сказать_V писать_V удивляться_V'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лишнее - удивляться.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
